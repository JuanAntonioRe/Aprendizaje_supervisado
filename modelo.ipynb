{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los clientes de Beta Bank se están yendo, cada mes, poco a poco. Los banqueros descubrieron que es más barato salvar a los clientes existentes que atraer nuevos.\n",
    "\n",
    "Es necesario predecir si un cliente dejará el banco pronto.\n",
    "\n",
    "Se creará un modelo con el máximo valor F1 posible. Para aprobar la revisión, necesitas un valor F1 de al menos 0.59. Se verifica F1 para el conjunto de prueba. \n",
    "\n",
    "Además, se debe medir la métrica AUC-ROC y compararla con el valor F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se descargarán los datos desde el archivo csv y se buscarán valores repetidos o ausentes. También se revisrá el tipo de datos de cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importación de librerías\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Descarga de los datos\n",
    "data = pd.read_csv('/datasets/Churn.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9132</th>\n",
       "      <td>9133</td>\n",
       "      <td>15737194</td>\n",
       "      <td>Tu</td>\n",
       "      <td>635</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>122949.71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9789</th>\n",
       "      <td>9790</td>\n",
       "      <td>15814040</td>\n",
       "      <td>Munroe</td>\n",
       "      <td>610</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>199657.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120</th>\n",
       "      <td>3121</td>\n",
       "      <td>15694879</td>\n",
       "      <td>Reeves</td>\n",
       "      <td>590</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>196789.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>777</td>\n",
       "      <td>15712551</td>\n",
       "      <td>Shen</td>\n",
       "      <td>622</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>58</td>\n",
       "      <td>7.0</td>\n",
       "      <td>116922.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120415.61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3736</th>\n",
       "      <td>3737</td>\n",
       "      <td>15607748</td>\n",
       "      <td>Bennett</td>\n",
       "      <td>498</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>37</td>\n",
       "      <td>8.0</td>\n",
       "      <td>108432.88</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14865.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId  Surname  CreditScore Geography  Gender  Age  \\\n",
       "9132       9133    15737194       Tu          635    France  Female   33   \n",
       "9789       9790    15814040   Munroe          610    France  Female   45   \n",
       "3120       3121    15694879   Reeves          590     Spain  Female   23   \n",
       "776         777    15712551     Shen          622   Germany  Female   58   \n",
       "3736       3737    15607748  Bennett          498   Germany    Male   37   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "9132     5.0       0.00              2          1               0   \n",
       "9789     1.0       0.00              2          1               1   \n",
       "3120     7.0       0.00              2          1               0   \n",
       "776      7.0  116922.25              1          1               0   \n",
       "3736     8.0  108432.88              2          1               1   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "9132        122949.71       0  \n",
       "9789        199657.46       0  \n",
       "3120        196789.90       0  \n",
       "776         120415.61       1  \n",
       "3736         14865.05       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cantidad de filas duplicadas: 0\n"
     ]
    }
   ],
   "source": [
    "# Se imprime una muestra de los datos y se buscan datos duplicados\n",
    "display(data.sample(5))\n",
    "print()\n",
    "print('Cantidad de filas duplicadas:', data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones:\n",
    "\n",
    "* La columna `'Tenure'` tiene 909 valores ausentes, los cuales representan un 9% del total de filas de los datos. La librería `scikit-learn` es incompatible para trabajar con datos ausentes. La cantidad de datos es considerable para que sean remplazados por valores constantes (como la media), esto creará un gran sesgo en los datos. Con esto se decide eliminar las filas que tienen valores ausentes en la columna `'Tenure'`.\n",
    "* La columna `'Surname'` será eliminada debido a la gran cantidad de apellidos que hay y al momento de realizar la codificación OHE habrán muchas columnas y los cálculos con la computadora tomarán mucho tiempo, además los apellidos no son de importancia cuando un usuario decide dejar el banco. Adicionalmente con la columna `'CustomerId'` se puede saber que usuario es.\n",
    "* También se ha decidido borrar las columnas `RowNumber` y `CustomerId`. Ya que son el índice de cadena de datos y el identificador de cliente único, respectivamente. Ninguno afecta al momento de que un cliente decide dejar la sucursal\n",
    "* Los tipos de datos están correctos\n",
    "* No hay datos duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9091 entries, 0 to 9998\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      9091 non-null   int64  \n",
      " 1   Geography        9091 non-null   object \n",
      " 2   Gender           9091 non-null   object \n",
      " 3   Age              9091 non-null   int64  \n",
      " 4   Tenure           9091 non-null   float64\n",
      " 5   Balance          9091 non-null   float64\n",
      " 6   NumOfProducts    9091 non-null   int64  \n",
      " 7   HasCrCard        9091 non-null   int64  \n",
      " 8   IsActiveMember   9091 non-null   int64  \n",
      " 9   EstimatedSalary  9091 non-null   float64\n",
      " 10  Exited           9091 non-null   int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 852.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Borrar filas con valores ausentes\n",
    "data = data.dropna()\n",
    "\n",
    "# Borra la columnas\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Codificación de características categóricas utilizando OHE y escalado de las características numéricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se transformarán las características categóricas en numéricas para utilizar modelos de regresión, evitando la trampa dummy. Después de esto, se dividirá el conjunto en las caracteríscticas y el objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación OHE\n",
    "data_ohe = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# División de características y objetivo\n",
    "target = data_ohe['Exited']\n",
    "features = data_ohe.drop('Exited', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hará la división de datos en los conjuntos de entrenamiento, validación y prueba. Para lograrlo se hará uso de `train_test_split` dos veces y así, poder separar el dataset en tres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de los conjuntos de etrenamiento y prueba\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size = 0.2, random_state=12345)\n",
    "\n",
    "# División de entrenamiento y validación\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features_train, target_train, test_size = 0.25, random_state=12345)\n",
    "# # Se usa 0.25 porque 0.8*0.25=0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se realizará el escalado de características y se volverá a dividir el conjunto de características en entrenamiento y validación, para que el modelo considere todas las características igual de importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5454, 11)\n",
      "(1818, 11)\n"
     ]
    }
   ],
   "source": [
    "# Primero sacaremos las columnas que que son numéricas desde el inicio\n",
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember',\n",
    "           'EstimatedSalary']\n",
    "\n",
    "# Escalado de características\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "\n",
    "# Comprobamos las filas y columnas\n",
    "print(features_train.shape)\n",
    "print(features_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento de modelos sin tomar en cuenta el desequilibrio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrenaran 3 modelos: Árbol de decisión, Bosque aleatorio y Regresión logística. A cada modelo se le obtendrá el valor F1 para tratar de aproximarnos al valor solicitado.\n",
    "\n",
    "También se ha solicitado que obtengamos el valor AUC-ROC de cada modelo y compararlos, por lo que también se calculará este valor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Árbol de regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a entrenar el modelo en diferentes profundidades de árbol para saber cuál es la profundidad que tiene el mayor valor F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del mejor modelo en el conjunto de validación (max_depth=9): 0.557427258805513\n"
     ]
    }
   ],
   "source": [
    "# Variables para guardar la mejor f1 con el max_depth\n",
    "best_f1_tree = 0\n",
    "best_depth = 0\n",
    "\n",
    "# Ciclo para evaluar el modelo en diferentes profundidades\n",
    "for depth in range(1,11):\n",
    "    model_tree = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model_tree.fit(features_train, target_train)\n",
    "    predictions_valid_tree = model_tree.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predictions_valid_tree)\n",
    "    if f1 > best_f1_tree:\n",
    "        best_depth = depth\n",
    "        best_f1_tree = f1\n",
    "\n",
    "print(f'F1 del mejor modelo en el conjunto de validación (max_depth={best_depth}): {best_f1_tree}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valor AUC-ROC.\n",
    "\n",
    "Para poder sacar este valor es necesario tomar las probabilidades de clase positiva y nos muestra el área bajo la curva de la característica operativa del receptor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC_ROC: 0.7799276294991645\n"
     ]
    }
   ],
   "source": [
    "# Probabilidades de clase\n",
    "probabilities_valid = model_tree.predict_proba(features_valid)\n",
    "\n",
    "# Probabilidades de clase positiva\n",
    "probabilities_one_valid = probabilities_valid[:,1]\n",
    "\n",
    "# valor AUC-ROC\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC_ROC:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusión:\n",
    "\n",
    "La mejor profundidad de árbol es de 7, cuyo valor es de 0.56, sin embargo, se nos solicitó que por lo menos tuviera un valor de 0.59. Este modelo queda descartado.\n",
    "\n",
    "El valor AUC-ROC es más grande que el F1 pero aún está lejos del 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Bosque aleatorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a entrenar el modelo en difirentes valores de `n_estimators` para saber cuál tiene mejor valor F1. Por motivos de cómputo, sólo se evaluarán hasta 10 árboles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del mejor modelo en el conjunto de validación (n_estimators=7): 0.523961661341853\n"
     ]
    }
   ],
   "source": [
    "# Variables para guardar la mejor f1 con el número de de árboles\n",
    "best_f1_forest = 0\n",
    "best_estimator = 0\n",
    "\n",
    "# Ciclo para evaluar el modelo en diferentes números de árboles\n",
    "for est in range(1,11):\n",
    "    model_forest = RandomForestClassifier(random_state=12345, n_estimators=est)\n",
    "    model_forest.fit(features_train, target_train)\n",
    "    predictions_valid_forest = model_forest.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predictions_valid_forest)\n",
    "    if f1 > best_f1_forest:\n",
    "        best_estimator = est\n",
    "        best_f1_forest = f1\n",
    "\n",
    "print(f'F1 del mejor modelo en el conjunto de validación (n_estimators={best_estimator}): {best_f1_forest}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valor AUC-ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC_ROC: 0.7948589847807433\n"
     ]
    }
   ],
   "source": [
    "# Probabilidades de clase\n",
    "probabilities_valid = model_forest.predict_proba(features_valid)\n",
    "\n",
    "# Probabilidades de clase positiva\n",
    "probabilities_one_valid = probabilities_valid[:,1]\n",
    "\n",
    "# valor AUC-ROC\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC_ROC:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusión:\n",
    "\n",
    "El mejor número de árbol es 8, cuyo valor es de 0.50, sin embargo, se nos solicitó que por lo menos tuviera un valor de 0.59. Este modelo queda descartado.\n",
    "\n",
    "El valor AUC-ROC es más grande que el F1 pero aún está lejos del 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrena el modelo con `solver=liblinear`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor F1: 0.3004115226337448\n"
     ]
    }
   ],
   "source": [
    "model_regression = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model_regression.fit(features_train, target_train)\n",
    "predictions_valid_regression = model_regression.predict(features_valid)\n",
    "f1_regression = f1_score(target_valid, predictions_valid_regression)\n",
    "print('Valor F1:', f1_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valor AUC-ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC_ROC: 0.7725917897303888\n"
     ]
    }
   ],
   "source": [
    "# Probabilidades de clase\n",
    "probabilities_valid = model_regression.predict_proba(features_valid)\n",
    "\n",
    "# Probabilidades de clase positiva\n",
    "probabilities_one_valid = probabilities_valid[:,1]\n",
    "\n",
    "# valor AUC-ROC\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC_ROC:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusión:\n",
    "\n",
    "El valor F1 del modelo es de 0.30, sin embargo, se nos solicitó que por lo menos tuviera un valor de 0.59. Este modelo queda descartado.\n",
    "\n",
    "El valor AUC-ROC es más grande que el F1 pero aún está lejos del 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos con desequilibrio de clases no alcanzaron el valor F1 que fue solicitado en el ejercicio. Ahora se harán los modelos austando ese desbalanceo.\n",
    "\n",
    "El valor F1 es muy variado entre cada modelo. Por otro lado, el valor AUC-ROC no cambia entre cada modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mejora de la calidad de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para lograr esto se harán dos enfoques para corregir el desequilibrio de clase: Sobremuestreo y submuestreo.\n",
    "\n",
    "En el sobremuestreo las tareas más importantes se repiten, mientras que en el submuestreo hcemos que las observaciones de clase más frecuentes sean menos frecuentes. Dicho esto, necesitamos averiguar que clase se repite más veces.\n",
    "\n",
    "Cuando sepamos cuál clase se repite más, se aplicarán los métodos antes mencionados para hacer que las clases estén más quelibradas. De cada método se obtendrán características y objetivos con los que se evaluará el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. ¿Cuál clase se repite más?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para saber cuál es la clase que más se repite se dividirán los datos de entrenamiento en observaciones negativas y positivas. Es decir, se realizarán filtros de las características y objetivo de entrenamiento donde el objetivo sea 0 y uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4335, 11)\n",
      "(1119, 11)\n",
      "(4335,)\n",
      "(1119,)\n"
     ]
    }
   ],
   "source": [
    "# División del conjunto de datos\n",
    "features_zeros = features_train[target_train==0]\n",
    "features_ones = features_train[target_train==1]\n",
    "target_zeros = target_train[target_train==0]\n",
    "target_ones = target_train[target_train==1]\n",
    "print(features_zeros.shape)\n",
    "print(features_ones.shape)\n",
    "print(target_zeros.shape)\n",
    "print(target_ones.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusión:\n",
    "\n",
    "Hay alrededor de 4 veces más observaciones negativas que positivas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Sobremuestreo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo con el ejercicio anterior, tenemos que duplicar las observaciones positivas. Para lograrlo se hace uso de la función `concat()` de la librería pandas. Se necesitará un multiplicador o repetidor para aumentar las observaciones positivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14406, 11)\n",
      "(14406,)\n"
     ]
    }
   ],
   "source": [
    "# Número de repeticiones\n",
    "repeat = 9\n",
    "\n",
    "# Características y objetivo aumentadas usando concat()\n",
    "features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "print(features_upsampled.shape)\n",
    "print(target_upsampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es necesario \"barajear\" los datos, para esto hacemos uso de la función `shuffle()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función shuffle()\n",
    "features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Submuestreo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esto haremos uso de los resultados del punto 4.1. Pero a diferencia del sobremuestreo, ahora se descartarán al azar una parte de las observaciones negativas haceindo uso de la función `sample()` con el parámetro `fracc`, porque tenemos que determinar que fracción de los datos queremos soltar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2853, 11)\n",
      "(2853,)\n"
     ]
    }
   ],
   "source": [
    "# Fracción a soltar\n",
    "fraction = 0.4\n",
    "\n",
    "# Descartar observaciones negativas con sample()\n",
    "features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "\n",
    "print(features_downsampled.shape)\n",
    "print(target_downsampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De igual manera que con el sobremuestreo, se tienen que barajear los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función shuffle()\n",
    "features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los datos equilibrados se volverán a entrenar los modelos de árboles de desición, bosque aleatorio y Regresión logística en cada conjunto: sobremuestreo y submuestreo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Árbol de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a entrenar el modelo en diferentes profundidades de árbol para saber cuál es la profundidad que tiene el mayor valor F1. También se obtendrá el valor AUC-ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.1. Conjunto con sobremuestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del mejor modelo en el conjunto de validación (max_depth=9): 0.5048715677590788\n"
     ]
    }
   ],
   "source": [
    "# Variables para guardar la mejor f1 con el max_depth\n",
    "best_f1_tree_up = 0\n",
    "best_depth = 0\n",
    "\n",
    "# Ciclo para evaluar el modelo en diferentes profundidades\n",
    "for depth in range(1,11):\n",
    "    model_tree_up = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model_tree_up.fit(features_upsampled, target_upsampled)\n",
    "    predictions_valid = model_tree_up.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predictions_valid)\n",
    "    if f1 > best_f1_tree_up:\n",
    "        best_depth = depth\n",
    "        best_f1_tree_up = f1\n",
    "\n",
    "print(f'F1 del mejor modelo en el conjunto de validación (max_depth={best_depth}): {best_f1_tree_up}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valor AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC_ROC: 0.7625726339399961\n"
     ]
    }
   ],
   "source": [
    "# Probabilidades de clase\n",
    "probabilities_valid = model_tree_up.predict_proba(features_valid)\n",
    "\n",
    "# Probabilidades de clase positiva\n",
    "probabilities_one_valid = probabilities_valid[:,1]\n",
    "\n",
    "# valor AUC-ROC\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC_ROC:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.2. Conjunto con submuestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del mejor modelo en el conjunto de validación (max_depth=5): 0.577127659574468\n"
     ]
    }
   ],
   "source": [
    "# Variables para guardar la mejor f1 con el max_depth\n",
    "best_f1_tree_down = 0\n",
    "best_depth = 0\n",
    "\n",
    "# Ciclo para evaluar el modelo en diferentes profundidades\n",
    "for depth in range(1,11):\n",
    "    model_tree_down = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model_tree_down.fit(features_downsampled, target_downsampled)\n",
    "    predictions_valid = model_tree_down.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predictions_valid)\n",
    "    if f1 > best_f1_tree_down:\n",
    "        best_depth = depth\n",
    "        best_f1_tree_down = f1\n",
    "\n",
    "print(f'F1 del mejor modelo en el conjunto de validación (max_depth={best_depth}): {best_f1_tree_down}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valor AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC_ROC: 0.7374179575185535\n"
     ]
    }
   ],
   "source": [
    "# Probabilidades de clase\n",
    "probabilities_valid = model_tree_down.predict_proba(features_valid)\n",
    "\n",
    "# Probabilidades de clase positiva\n",
    "probabilities_one_valid = probabilities_valid[:,1]\n",
    "\n",
    "# valor AUC-ROC\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC_ROC:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones:\n",
    "\n",
    "No se logra el valor F1 deseado, de es más bajo con ambos conjuntos mejorados, de igual manera el valor AUC-ROC es más bajo en los dos conuntos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Bosque Aleatorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a entrenar el modelo en difirentes valores de `n_estimators` para saber cuál tiene mejor valor F1. Por motivos de cómputo, sólo se evaluarán hasta 10 árboles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1. Conjunto con sobremuestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del mejor modelo en el conjunto de validación (n_estimators=9): 0.5891016200294551\n"
     ]
    }
   ],
   "source": [
    "# Variables para guardar la mejor f1 con el número de de árboles\n",
    "best_f1_forest_up = 0\n",
    "best_estimator = 0\n",
    "\n",
    "# Ciclo para evaluar el modelo en diferentes números de árboles\n",
    "for est in range(1,11):\n",
    "    model_forest_up = RandomForestClassifier(random_state=12345, n_estimators=est)\n",
    "    model_forest_up.fit(features_upsampled, target_upsampled)\n",
    "    predictions_valid_forest = model_forest_up.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predictions_valid_forest)\n",
    "    if f1 > best_f1_forest_up:\n",
    "        best_estimator = est\n",
    "        best_f1_forest_up = f1\n",
    "\n",
    "print(f'F1 del mejor modelo en el conjunto de validación (n_estimators={best_estimator}): {best_f1_forest_up}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valor AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC_ROC: 0.8247518026765419\n"
     ]
    }
   ],
   "source": [
    "# Probabilidades de clase\n",
    "probabilities_valid = model_forest_up.predict_proba(features_valid)\n",
    "\n",
    "# Probabilidades de clase positiva\n",
    "probabilities_one_valid = probabilities_valid[:,1]\n",
    "\n",
    "# valor AUC-ROC\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC_ROC:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.2. Conjunto con submuestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del mejor modelo en el conjunto de validación (n_estimators=10): 0.5392953929539295\n"
     ]
    }
   ],
   "source": [
    "# Variables para guardar la mejor f1 con el número de de árboles\n",
    "best_f1_forest_down = 0\n",
    "best_estimator = 0\n",
    "\n",
    "# Ciclo para evaluar el modelo en diferentes números de árboles\n",
    "for est in range(1,11):\n",
    "    model_forest_down = RandomForestClassifier(random_state=12345, n_estimators=est)\n",
    "    model_forest_down.fit(features_downsampled, target_downsampled)\n",
    "    predictions_valid_forest = model_forest_down.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predictions_valid_forest)\n",
    "    if f1 > best_f1_forest_down:\n",
    "        best_estimator = est\n",
    "        best_f1_forest_down = f1\n",
    "\n",
    "print(f'F1 del mejor modelo en el conjunto de validación (n_estimators={best_estimator}): {best_f1_forest_down}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valor AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC_ROC: 0.800109891764139\n"
     ]
    }
   ],
   "source": [
    "# Probabilidades de clase\n",
    "probabilities_valid = model_forest_down.predict_proba(features_valid)\n",
    "\n",
    "# Probabilidades de clase positiva\n",
    "probabilities_one_valid = probabilities_valid[:,1]\n",
    "\n",
    "# valor AUC-ROC\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC_ROC:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones:\n",
    "\n",
    "El valor F1 mejoró en ambos conjuntos, así como el valor mejoró el valor AUC-ROC. Pero, aún no se logra el valor F1 esperado de 0.59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrena el modelo con `solver=liblinear`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.1. Conjunto con sobremuestro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor F1: 0.42993024730500945\n"
     ]
    }
   ],
   "source": [
    "model_regression_up = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model_regression_up.fit(features_upsampled, target_upsampled)\n",
    "predictions_valid_regression = model_regression_up.predict(features_valid)\n",
    "f1_regression_up = f1_score(target_valid, predictions_valid_regression)\n",
    "print('Valor F1:', f1_regression_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valor AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC_ROC: 0.7747651628054012\n"
     ]
    }
   ],
   "source": [
    "# Probabilidades de clase\n",
    "probabilities_valid = model_regression_up.predict_proba(features_valid)\n",
    "\n",
    "# Probabilidades de clase positiva\n",
    "probabilities_one_valid = probabilities_valid[:,1]\n",
    "\n",
    "# valor AUC-ROC\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC_ROC:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.2. Conjunto con submuestro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor F1: 0.4920212765957447\n"
     ]
    }
   ],
   "source": [
    "model_regression_down = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model_regression_down.fit(features_downsampled, target_downsampled)\n",
    "predictions_valid_regression = model_regression_down.predict(features_valid)\n",
    "f1_regression_down = f1_score(target_valid, predictions_valid_regression)\n",
    "print('Valor F1:', f1_regression_down)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valor AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC_ROC: 0.7743794126059401\n"
     ]
    }
   ],
   "source": [
    "# Probabilidades de clase\n",
    "probabilities_valid = model_regression_down.predict_proba(features_valid)\n",
    "\n",
    "# Probabilidades de clase positiva\n",
    "probabilities_one_valid = probabilities_valid[:,1]\n",
    "\n",
    "# valor AUC-ROC\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC_ROC:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones:\n",
    "\n",
    "No se logra el valor F1 deseado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7. Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se evaluarón diferentes valores de `'repeat'` para el sobremuestreo y de `'fraction'` para el submuestreo, encontrando los mejores valores que se muestran debajo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeat = 9, fraction = 0.4\n",
      "Árbol de decisión: normal = 0.557427258805513, sobremuestreo = 0.5048715677590788, submuestreo = 0.577127659574468\n",
      "Bosque aleatorio: normal = 0.523961661341853, sobremuestreo = 0.5891016200294551, submuestreo = 0.5392953929539295\n",
      "Regresión logística: normal = 0.3004115226337448, sobremuestreo = 0.42993024730500945, submuestreo = 0.4920212765957447\n"
     ]
    }
   ],
   "source": [
    "print(f'repeat = {repeat}, fraction = {fraction}')\n",
    "\n",
    "print(f'Árbol de decisión: normal = {best_f1_tree}, sobremuestreo = {best_f1_tree_up}, submuestreo = {best_f1_tree_down}')\n",
    "print(f'Bosque aleatorio: normal = {best_f1_forest}, sobremuestreo = {best_f1_forest_up}, submuestreo = {best_f1_forest_down}')\n",
    "print(f'Regresión logística: normal = {f1_regression}, sobremuestreo = {f1_regression_up}, submuestreo = {f1_regression_down}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor más cercano de 0.59 es con el modelo de bosque aleatorio con el conjunto de sobremuestreo con un valor de F1 = 0.589, por lo tanto este es el modelo que se ocupará para el conjunto de prueba.\n",
    "\n",
    "Como se puede ver en el apartado 4.5.1. El `n_estimators` con el que dió dicho resultado es 9.\n",
    "\n",
    "Además también es el modelo con el mejor valor AUC-ROC, el cuál es de 0.824"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prueba final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder evaluar el conjunto de prueba, se van a estandarizar las variables usando `StandardScaler()`. Esto debido a que en los temas anteriores no se había realizado este proceso con el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/2157777557.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_test[numeric] = scaler_test.transform(features_test[numeric])\n",
      "/opt/conda/lib/python3.9/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "# Escalado del conjunto de prueba\n",
    "scaler_test = StandardScaler()\n",
    "scaler_test.fit(features_test[numeric])\n",
    "features_test[numeric] = scaler_test.transform(features_test[numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor F1 del conjunto de prueba: 0.5310734463276837\n"
     ]
    }
   ],
   "source": [
    "final_model = RandomForestClassifier(random_state=12345, n_estimators=9)\n",
    "final_model.fit(features_upsampled, target_upsampled)\n",
    "predictions_test = final_model.predict(features_test)\n",
    "f1_test = f1_score(target_test, predictions_test)\n",
    "print('Valor F1 del conjunto de prueba:', f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusión:\n",
    "\n",
    "EL valor F1 del conjunto de prueba es de 0.513, el cuál es un poco por debajo de lo que se nos pide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
